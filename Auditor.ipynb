{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML+ocaizIfsD+i80GO50r2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyashDhoot/TiPAI-TSPO/blob/main/Auditor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9enShGDJOOM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import requests\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "collapsed": true,
        "id": "O5Ko4-sXJSpA",
        "outputId": "b07fa6fe-c5fe-452f-c66c-42f306786046"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3549498780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"ShreyashDhoot/KTO_trial\",split='train',streaming=True)"
      ],
      "metadata": {
        "id": "KZ-9S31-JUub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###setting up CLIP model\n",
        "model_name=\"resnet50_clip.openai\"\n",
        "model=timm.create_model(model_name,\n",
        "                        pretrained=True,\n",
        "                        features_only=True,\n",
        "                        out_indices=[4] # <= gets output from layer 4\n",
        "                        )\n",
        "## puts model in eval mode\n",
        "model.eval()\n",
        "## shifts model on target device\n",
        "model.to(device)\n",
        "## gets the data configuration for pretrained models\n",
        "data_config=timm.data.resolve_model_data_config(model)\n",
        "## processes data according to config\n",
        "processor = timm.data.create_transform(**data_config,is_training=False)"
      ],
      "metadata": {
        "id": "1PK4J2pvJVRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. writing a function for getting training images\n",
        "def get_batch_images(batch,device):\n",
        "  images=[processor(img.convert('RGB')) for img in batch['image']]\n",
        "  labels=torch.tensor(batch['label']).float().to(device).unsqueeze(1)\n",
        "  return torch.stack(images).to(device),labels"
      ],
      "metadata": {
        "id": "PyHrgB6zJXKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. defining the model\n",
        "class BCE_pair_path(nn.Module):\n",
        "  def __init__(self,input_classes=2048,num_classes=1):\n",
        "    super().__init__()\n",
        "    self.risk_conv=nn.Conv2d(input_classes,1,kernel_size=1)\n",
        "    self.pool=nn.AdaptiveMaxPool2d((1,1))\n",
        "    self.mlp=nn.Sequential(nn.Linear(1,16),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(16,1))\n",
        "  def forward(self,x):\n",
        "    risk_map=self.risk_conv(x)\n",
        "    intermediate_logits=self.pool(risk_map)\n",
        "    flattened_logits=torch.flatten(intermediate_logits,1)\n",
        "    logits=self.mlp(flattened_logits)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "l5t-nXBfJcU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. defining the BCE loss and making the hook\n",
        "model_3=BCE_pair_path().to(device)\n",
        "loss_fn_bce=nn.BCEWithLogitsLoss()\n",
        "optimizer=torch.optim.Adam(params=model_3.parameters(),lr=0.001)\n",
        "\n",
        "activations={}\n",
        "\n",
        "def get_activations_hook(name):\n",
        "  def hook(model,input,output):\n",
        "    activations[name]=output\n",
        "  return hook\n",
        "\n",
        "handle=model_3.risk_conv.register_forward_hook(get_activations_hook('risk_map'))"
      ],
      "metadata": {
        "id": "OvtwEazhJemM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. defining pair wise loss\n",
        "def loss_fn_pairwise(logits,labels):\n",
        "  \"\"\"\n",
        "  L_pair = mean( log(1 + exp(-(S+i - S-j))) )\n",
        "  \"\"\"\n",
        "  s_plus=logits[labels==1] #<=== selects logits whose true label is 1\n",
        "  s_minus=logits[labels==0] #<===== selects logits whose true label is 0\n",
        "  if s_plus.numel()==0 or s_minus.numel()==0:\n",
        "    return torch.tensor(0.0,device=logits.device,requires_grad=True)\n",
        "\n",
        "  diff_matrix= s_plus.unsqueeze(1)-s_minus.unsqueeze(0)\n",
        "\n",
        "  loss_matrix = torch.log(1+torch.exp(-diff_matrix))\n",
        "\n",
        "  return loss_matrix.mean()"
      ],
      "metadata": {
        "id": "otoraBbhJgS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. lets define patch wise loss\n",
        "def loss_fn_patch(risk_map,lables,k=11):\n",
        "  batch_size=risk_map.shape[0]\n",
        "  flat_map=risk_map.view(batch_size,-1)\n",
        "  topk_values,_=torch.topk(flat_map,k,dim=1)\n",
        "\n",
        "  mask_1 = (labels.view(-1) == 1)\n",
        "  mask_0 = (labels.view(-1)==0)\n",
        "  s_patch_plus=topk_values[mask_1]\n",
        "  s_patch_minus=topk_values[mask_0]\n",
        "\n",
        "  if s_patch_plus.numel()==0 or s_patch_minus.numel()==0:\n",
        "    return torch.tensor(0.0, device=risk_map.device,requires_grad=True)\n",
        "\n",
        "  s_plus_flat=s_patch_plus.reshape(-1)\n",
        "  s_minus_flat=s_patch_minus.reshape(-1)\n",
        "\n",
        "  diffs=s_plus_flat.unsqueeze(1)-s_minus_flat.unsqueeze(0)\n",
        "\n",
        "  loss_patch=torch.log(1+torch.exp(-diffs)).mean()\n",
        "\n",
        "  return loss_patch"
      ],
      "metadata": {
        "id": "GeoeolCKJiVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. plot heatmap\n",
        "def plot_heatmap(image_tensor,risk_map_tensor):\n",
        "  # get tensors back on cpu and change their orientation put channel at last\n",
        "  img=image_tensor.cpu().permute(1,2,0).numpy()\n",
        "  ## undo image normalization\n",
        "  img =(img - img.min())/(img.max() - img.min())\n",
        "\n",
        "  heatmap = torch.sigmoid(risk_map_tensor)\n",
        "  heatmap = F.interpolate(heatmap.unsqueeze(0),size=(224,224),mode='bilinear')[0,0]\n",
        "  heatmap=heatmap.detach().cpu().numpy()\n",
        "\n",
        "  fig, (ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
        "  ax1.imshow(img)\n",
        "  ax1.set_title(\"original image\")\n",
        "  ax1.axis('off')\n",
        "\n",
        "  ax2.imshow(img)\n",
        "  im=ax2.imshow(heatmap,cmap=\"jet\",alpha=0.5)\n",
        "  ax2.set_title(\"Risk Heatmap\")\n",
        "  ax2.axis('off')\n",
        "\n",
        "  plt.colorbar(im,ax=ax2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uxyPipJrJkbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs=1\n",
        "lambda_bce=1\n",
        "lambda_pair=1\n",
        "lambda_patch=1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  batched_dataset=dataset.batch(batch_size=32)\n",
        "  epoch_loss=0\n",
        "  for batch_number,batch in enumerate(tqdm(batched_dataset)):\n",
        "    images,labels=get_batch_images(batch,device)\n",
        "    with torch.no_grad():\n",
        "      clip_logits = model(images)[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_logits=model_3(clip_logits)\n",
        "    current_heatmaps=activations['risk_map']\n",
        "    # BCE loss\n",
        "    l_bce=loss_fn_bce(train_logits,labels)\n",
        "    #pairwise loss\n",
        "    l_pair=loss_fn_pairwise(train_logits,labels)\n",
        "    #patch wise loss\n",
        "    l_patch=loss_fn_patch(current_heatmaps,labels,k=11)\n",
        "\n",
        "    total_loss=(lambda_bce * l_bce)+(lambda_pair * l_pair)+(lambda_patch * l_patch)\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += total_loss.item()\n",
        "\n",
        "    if batch_number % 10 == 0:\n",
        "      with torch.no_grad():\n",
        "      # Calculate the \"Gap\" for monitoring\n",
        "        pos_avg = train_logits[labels==1].mean().item() if (labels==1).any() else 0\n",
        "        neg_avg = train_logits[labels==0].mean().item() if (labels==0).any() else 0\n",
        "        gap = pos_avg - neg_avg\n",
        "        print(f\"Batch {batch_number} | BCE: {l_bce:.3f} | Pair: {l_pair:.3f} | Patch: {l_patch:.3f} | Gap: {gap:.3f}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    if batch_number % 50 == 0:\n",
        "      # Plot the first image in the batch and its corresponding heatmap\n",
        "      plot_heatmap(images[0], current_heatmaps[0])\n",
        "      print(f\"Image label = {labels[0]}\")\n"
      ],
      "metadata": {
        "id": "UymbSeD1Jmqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kClRsZKvJxGW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}